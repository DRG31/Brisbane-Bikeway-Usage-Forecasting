{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Task 1: Data Preparation\n",
    "\n",
    "Load raw data from 2016-2020 into separate DataFrames\n",
    "\n",
    "Handle missing values by replacing zeros with mean of each column\n",
    "\n",
    "Extract total daily cyclist data for Bicentennial Bikeway Milton from appropriate columns\n",
    "\n",
    "Concatenate DataFrames into single time series\n",
    "\n",
    "Add weather data (temperature, humidity etc) by merging on datetime index\n",
    "\n",
    "Set datetime index and localize to Australia/Melbourne timezone\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-05-02T14:46:19.096669900Z",
     "start_time": "2024-05-02T14:46:17.979383600Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Assignment 3 data(1)/bike-ped-auto-counts-2016.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 11\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Task 1: Data Preparation\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# Load the 5 data files into separate dataframes\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m df2016 \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAssignment 3 data(1)/bike-ped-auto-counts-2016.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \n\u001B[0;32m     12\u001B[0m df2017 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAssignment 3 data(1)/bike-ped-auto-counts-2017.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     13\u001B[0m df2018 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAssignment 3 data(1)/bike-ped-auto-counts-2018.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)  \n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    945\u001B[0m )\n\u001B[0;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'Assignment 3 data(1)/bike-ped-auto-counts-2016.csv'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Task 1: Data Preparation\n",
    "\n",
    "# Load the 5 data files into separate dataframes\n",
    "df2016 = pd.read_csv('Assignment 3 data(1)/bike-ped-auto-counts-2016.csv') \n",
    "df2017 = pd.read_csv('Assignment 3 data(1)/bike-ped-auto-counts-2017.csv')\n",
    "df2018 = pd.read_csv('Assignment 3 data(1)/bike-ped-auto-counts-2018.csv')  \n",
    "df2019 = pd.read_csv('Assignment 3 data(1)/bike-ped-auto-counts-2019.csv')\n",
    "df2020 = pd.read_csv('Assignment 3 data(1)/bike-ped-auto-counts-2020.csv')\n",
    "df_w = pd.read_csv('Weather.csv') \n",
    "dfw = pd.read_csv('Weather1.csv')\n",
    "\n",
    "wdf = pd.concat([df_w,dfw])\n",
    "\n",
    "for tdf in [df2016, df2017, df2018, df2019, df2020]:\n",
    "  tdf.columns = tdf.columns.str.replace(',', '')\n",
    "  for column in tdf.columns:\n",
    "    if pd.api.types.is_numeric_dtype(tdf[column]):\n",
    "     mean_value = tdf[column][tdf[column] != 0].mean()\n",
    "     tdf[column] = tdf[column].replace(0, mean_value)\n",
    "     tdf[column].fillna(mean_value, inplace=True)\n",
    "\n",
    "df2020.rename(columns={'Time': 'Date'}, inplace=True)\n",
    "wdf.rename(columns={'datetime': 'Date'}, inplace=True)\n",
    "\n",
    "\n",
    "# Extract total cyclists for Bicentennial Bikeway, Milton\n",
    "df2016['Bicentennial Bikeway Milton Total Cyclists'] = df2016['Bicentennial Bikeway Cyclists Inbound'] + df2016['Bicentennial Bikeway Cyclists Outbound']\n",
    "df2016=df2016[['Date','Bicentennial Bikeway Cyclists Inbound','Bicentennial Bikeway Cyclists Outbound','Bicentennial Bikeway Milton Total Cyclists']]\n",
    "\n",
    "df2017['Bicentennial Bikeway Milton Total Cyclists'] = df2017['Bicentennial Bikeway Cyclists Inbound'] + df2017['Bicentennial Bikeway Cyclists Outbound']\n",
    "df2017=df2017[['Date','Bicentennial Bikeway Cyclists Inbound','Bicentennial Bikeway Cyclists Outbound','Bicentennial Bikeway Milton Total Cyclists']]\n",
    "\n",
    "df2018['Bicentennial Bikeway Milton Total Cyclists'] = df2018['Bicentennial Bikeway Cyclists Inbound'] + df2018['Bicentennial Bikeway Cyclists Outbound']\n",
    "df2018=df2018[['Date','Bicentennial Bikeway Cyclists Inbound','Bicentennial Bikeway Cyclists Outbound','Bicentennial Bikeway Milton Total Cyclists']]\n",
    "\n",
    "df2019['Bicentennial Bikeway Milton Total Cyclists'] = df2019['A019 Bicentennial Bikeway Milton Cyclists'] \n",
    "df2019=df2019[['Date','A019 Bicentennial Bikeway Milton Cyclists','Bicentennial Bikeway Milton Total Cyclists']]\n",
    "\n",
    "df2020['Bicentennial Bikeway Milton Total Cyclists'] = df2020['A019 Bicentennial Bikeway Milton Cyclist'] \n",
    "df2020=df2020[['Date','A019 Bicentennial Bikeway Milton Cyclist','Bicentennial Bikeway Milton Total Cyclists']]\n",
    "\n",
    "wdf=wdf[['Date','temp','dew','humidity','precip']]\n",
    "\n",
    "\n",
    "for t_df in [df2016, df2017, df2018,df2019,df2020]:\n",
    " t_df.set_index('Date', inplace=True)\n",
    " t_df.index = pd.to_datetime(t_df.index, format='%d/%m/%Y')\n",
    " t_df.index = t_df.index.astype('datetime64[ns]')\n",
    " t_df.index = t_df.index.tz_localize('UTC').tz_convert('Australia/Melbourne')\n",
    "\n",
    "wdf.set_index('Date', inplace=True)\n",
    "wdf.index = pd.to_datetime(wdf.index,format='mixed')\n",
    "wdf.index = wdf.index.astype('datetime64[ns]')\n",
    "wdf.index = wdf.index.tz_localize('UTC').tz_convert('Australia/Melbourne')\n",
    "\n",
    "df=pd.concat([df2016,df2017,df2018,df2019,df2020])\n",
    "df = df.merge(wdf, on='Date')\n",
    "\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "print(\"Included weather data as potentially useful exogenous variables for the bike usage time series analysis.\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Task 2: Exploratory Data Analysis\n",
    "\n",
    "Visualized timeseries plot to observe overall trend and seasonal patterns\n",
    "\n",
    "Generated correlation heatmap to analyze relationships between variables\n",
    "\n",
    "Plotted histogram to check distribution and uncertainty\n",
    "\n",
    "From plots, identified increasing secular trend, strong seasonal peaks, positive correlation with temperature, and normal uncertainty distribution\n",
    "\n",
    "Used Weather as Side data and visualised its co relation matrix for results which seems directly related\n",
    "\n",
    "weather data link: https://www.visualcrossing.com/weather/weather-data-services#"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.153408500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Task 2: EDA\n",
    "\n",
    "# Timeseries plot\n",
    "df['Bicentennial Bikeway Milton Total Cyclists'].plot()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Cyclists')\n",
    "plt.title('Bicentennial Bikeway Milton')\n",
    "\n",
    "\n",
    "# Correlation heatmap\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Set the figure size to adjust for readability\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create the correlation matrix heatmap\n",
    "plt.imshow(corr_matrix, cmap='coolwarm', interpolation='none', aspect='auto')\n",
    "\n",
    "# Set x and y tick labels\n",
    "plt.xticks(range(len(df.columns)), df.columns, rotation=90)\n",
    "plt.yticks(range(len(df.columns)), df.columns)\n",
    "\n",
    "plt.colorbar()  # Add a color bar\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Distribution plot to show uncertainty  \n",
    "df['Bicentennial Bikeway Milton Total Cyclists'].plot.hist()\n",
    "\n",
    "# Discussion \n",
    "print(\"Timeseries plot shows an increasing trend over time with seasonal peaks and troughs. Correlation matrix indicates positive correlation with temperature. Uncertainty appears normally distributed. Seasonal decomposition highlights increasing secular trend and strong yearly seasonality pattern in the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.155427100Z"
    }
   },
   "outputs": [],
   "source": [
    "df['2020-10-01':'2020-12-31']['Bicentennial Bikeway Milton Total Cyclists'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.157425500Z"
    }
   },
   "outputs": [],
   "source": [
    "df['month']=df.index.month_name()\n",
    "df['hour'] = df.index.hour\n",
    "df['day_of_week']  = df.index.day_name()\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.158600300Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Line plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x='Date', y='Bicentennial Bikeway Milton Total Cyclists')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Cyclists')\n",
    "plt.title('Bicentennial Bikeway Milton - Line Plot')\n",
    "plt.show()\n",
    "\n",
    "# Box plot to show data distribution by year\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df.index.year, y='Bicentennial Bikeway Milton Total Cyclists', data=df)\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Cyclists')\n",
    "plt.title('Bicentennial Bikeway Milton - Box Plot by Year')\n",
    "plt.show()\n",
    "\n",
    "# Bar plot to show the average total cyclists by month\n",
    "df['Month'] = df.index.month\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Month', y='Bicentennial Bikeway Milton Total Cyclists', data=df, errorbar='sd')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Total Cyclists')\n",
    "plt.title('Bicentennial Bikeway Milton - Average Total Cyclists by Month')\n",
    "plt.show()\n",
    "\n",
    "# Discussion\n",
    "print(\"The line plot shows the trend-line, allowing us to observe the variation in data at each time point. The box plot provides a visual representation of data distribution by year, highlighting any yearly patterns. The bar plot shows the average total cyclists by month, helping us understand monthly variations in cyclist traffic.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Task 3: Focus on Bicentennial Bikeway Milton\n",
    "\n",
    "Split data into training (2017-2020) and testing (last 3 months of 2020) sets\n",
    "\n",
    "Performed seasonal decomposition on training data using statsmodels\n",
    "\n",
    "Plotted and analyzed trend, seasonal, and residual components\n",
    "\n",
    "Trend shows increasing baseline over time\n",
    "\n",
    "Clear yearly seasonal pattern visible\n",
    "\n",
    "Residuals seem to be random noise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.470990500Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Split data \u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2017-01-01\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2020-12-31\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      3\u001B[0m test \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2020-10-01\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2020-12-31\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Decompose training data\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Split data \n",
    "train = df['2017-01-01':'2020-12-31']\n",
    "test = df['2020-10-01':'2020-12-31']\n",
    "\n",
    "# Decompose training data\n",
    "decomposition = seasonal_decompose(train['Bicentennial Bikeway Milton Total Cyclists'])\n",
    "\n",
    "# Plot and interpret components\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(6,8))\n",
    "\n",
    "axes[0].plot(decomposition.observed)\n",
    "axes[0].set_title('Observed data')\n",
    "axes[0].set_ylabel('Cyclists')\n",
    "\n",
    "axes[1].plot(decomposition.trend)\n",
    "axes[1].set_title('Increasing trend')\n",
    "axes[1].set_ylabel('Cyclists')\n",
    "\n",
    "axes[2].plot(decomposition.seasonal)\n",
    "axes[2].set_title('Yearly seasonal pattern')\n",
    "axes[2].set_ylabel('Cyclists')\n",
    "\n",
    "axes[3].plot(decomposition.resid)\n",
    "axes[3].set_title('Residual noise')  \n",
    "axes[3].set_ylabel('Cyclists')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print('Automatic Decomposition shows an increasing secular trend, strong yearly seasonal pattern, and residual noise in the cyclist data.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Task 4: Timeseries Modeling\n",
    "\n",
    "Fit ARIMA(2,3,1) model on trend component of training data\n",
    "\n",
    "AR(1) and AR(2) parameters show decay factor and short term reversals\n",
    "\n",
    "Generated 1-step ahead forecasts on test set using ARIMA\n",
    "\n",
    "Added back seasonal component to get full forecasts\n",
    "\n",
    "Visualized forecasts and prediction intervals based on model confidence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.763763100Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Split the data into training and testing series\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2017-01-01\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2020-12-31\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      3\u001B[0m test \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2020-10-01\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2020-12-31\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Manual STR decomposition on training data for cyclist traffic\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing series\n",
    "train = df['2017-01-01':'2020-12-31']\n",
    "test = df['2020-10-01':'2020-12-31']\n",
    "\n",
    "# Manual STR decomposition on training data for cyclist traffic\n",
    "df_cyclists = pd.DataFrame(train['Bicentennial Bikeway Milton Total Cyclists'])\n",
    "\n",
    "# Resample to daily frequency\n",
    "df_cyclists = df_cyclists.resample('1D').mean()\n",
    "\n",
    "# Calculate the rolling 24-hour moving average\n",
    "df_cyclists['MA-24'] = df_cyclists['Bicentennial Bikeway Milton Total Cyclists'].rolling(24, min_periods=1).mean()\n",
    "\n",
    "# Calculate the seasonal component\n",
    "raw_monthly_means = df_cyclists.groupby(df_cyclists.index.to_period('M'))['MA-24'].mean()\n",
    "adjustment = raw_monthly_means.sum() / len(df_cyclists.index.to_period('M').unique())\n",
    "monthly_means = raw_monthly_means - adjustment\n",
    "seasonal = np.tile(monthly_means, len(df_cyclists.index.to_period('M').unique()))\n",
    "df_cyclists['temp-seasonal'] = seasonal[:len(df_cyclists)]\n",
    "\n",
    "# Calculate the detrended component\n",
    "df_cyclists['temp-detrended'] = df_cyclists['Bicentennial Bikeway Milton Total Cyclists'] - df_cyclists['MA-24']\n",
    "\n",
    "# Visualize the decomposition components\n",
    "fig, ax_str = plt.subplots(4, figsize=(18, 20))\n",
    "df_cyclists['Bicentennial Bikeway Milton Total Cyclists'].plot(label='Original', ax=ax_str[0])\n",
    "df_cyclists['MA-24'].plot(color='orange', label='MA-24 Trend', ax=ax_str[1])\n",
    "df_cyclists['temp-seasonal'].plot(color='blue', label='Seasonal', ax=ax_str[2])\n",
    "df_cyclists['temp-detrended'].plot(color='green', label='Residual', ax=ax_str[3])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.781906100Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cyclists['MA-24'].plot(color='orange', figsize=(24,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.782908400Z"
    }
   },
   "outputs": [],
   "source": [
    "trend_d1 = df_cyclists['MA-24'].diff()\n",
    "trend_d1.plot(figsize=(24,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.783906200Z"
    }
   },
   "outputs": [],
   "source": [
    "trend_d2 = trend_d1.diff()\n",
    "trend_d2.plot(figsize=(24,6),color='blue',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.786117400Z"
    }
   },
   "outputs": [],
   "source": [
    "trend_d3 = trend_d2.diff()\n",
    "trend_d3.plot(figsize=(24,6),color='blue',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.787129200Z"
    }
   },
   "outputs": [],
   "source": [
    "arima_1_3_0 = ARIMA(df_cyclists['MA-24'], order=(1, 3, 0)).fit()\n",
    "print(arima_1_3_0.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.789458900Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 12))\n",
    "fig = arima_1_3_0.plot_diagnostics(fig=fig, lags=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.790455600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit ARIMA model to the trend-cycle component\n",
    "arima_2_3_1 = ARIMA(df_cyclists['MA-24'], order=(2, 3, 1)).fit()\n",
    "print(arima_2_3_1.summary())\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "fig = arima_2_3_1.plot_diagnostics(fig=fig, lags=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.791455500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate forecasts using ARIMA model\n",
    "arima_fcst = arima_2_3_1.get_forecast(steps=len(test))\n",
    "arima_predictions = pd.DataFrame(arima_fcst.predicted_mean)\n",
    "arima_predictions.rename(columns={\"predicted_mean\": \"trend\"}, inplace=True)\n",
    "\n",
    "# Calculate and visualize trend+seasonal forecasts\n",
    "arima_predictions['seasonal'] = seasonal[:len(test)].tolist()\n",
    "arima_predictions['trend+seasonal'] = arima_predictions['trend'] + arima_predictions['seasonal']\n",
    "\n",
    "# Plot original data and trend+seasonal forecasts\n",
    "fig, ax_arima_fcst = plt.subplots(figsize=(24, 6))\n",
    "df_cyclists['Bicentennial Bikeway Milton Total Cyclists']['2017-09-30':'2020-12-31'].plot(label='Original', ax=ax_arima_fcst)\n",
    "arima_predictions['trend+seasonal'].plot(label=\"ARIMA(2,2,1) Trend+Seasonal Forecast\", ax=ax_arima_fcst)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.792500500Z"
    }
   },
   "outputs": [],
   "source": [
    "arima_predictions = pd.concat([arima_predictions,arima_fcst.conf_int()], axis = 1)\n",
    "arima_predictions.rename(columns={\"lower MA-24\": \"trend lower CI\", \"upper MA-24\": \"trend upper CI\"}, inplace=True)\n",
    "arima_predictions[\"seasonal lower CI\"] = arima_predictions[\"trend lower CI\"] + arima_predictions['seasonal']\n",
    "arima_predictions[\"seasonal upper CI\"] = arima_predictions[\"trend upper CI\"] + arima_predictions['seasonal']\n",
    "arima_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.793506200Z"
    }
   },
   "outputs": [],
   "source": [
    "x = arima_predictions.index.values\n",
    "fig, ax_arima_fcst = plt.subplots(figsize=(24,6))\n",
    "df_cyclists[\"2017-01-01\":\"2020-12-31\"]['Bicentennial Bikeway Milton Total Cyclists'].plot(label='Original', ax=ax_arima_fcst)\n",
    "arima_predictions['trend+seasonal'].plot(color = 'orange',label = 'Predicted' )\n",
    "arima_predictions['seasonal upper CI'].plot(color = 'grey', label = 'Upper CI')\n",
    "arima_predictions['seasonal lower CI'].plot(color = 'grey', label = 'Lower CI')\n",
    "\n",
    "# plot the legend for the first plot\n",
    "plt.legend(loc = 'lower left', fontsize = 12)\n",
    "\n",
    "# fill between the conf intervals\n",
    "plt.fill_between(x, arima_predictions['seasonal lower CI'], arima_predictions['seasonal upper CI'], color='grey', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Task 5: Pure Forecasting\n",
    "\n",
    "Built LSTM neural network architecture with 1 LSTM layer\n",
    "\n",
    "Trained model to predict trend component of training set\n",
    "\n",
    "Generated multistep forecasts on test set using LSTM\n",
    "\n",
    "Added back seasonal component\n",
    "\n",
    "Visualized LSTM predictions against actual data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.887832Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cyclists' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdf_cyclists\u001B[49m\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m100\u001B[39m))\n\u001B[0;32m      3\u001B[0m data_np \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(df_cyclists)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_cyclists' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(df_cyclists.head(100))\n",
    "data_np = np.array(df_cyclists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# train test split\n",
    "train, test = data_np[0:-1200], data_np[-1000:]\n",
    "# Scale\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.transform(test)\n",
    "\n",
    "# training data\n",
    "y_train = train_scaled[:,0]\n",
    "X_train = train_scaled[:,1:]\n",
    "\n",
    "# test data\n",
    "y_test = test_scaled[:,0]\n",
    "X_test = test_scaled[:,1:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.898879100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Configure model\n",
    "learning_rate = 0.0001\n",
    "\n",
    "def slff_relu(input_dim,hidden_1_dim = 64):\n",
    "    inputs = keras.layers.Input(shape=(input_dim))\n",
    "    hidden_layer_1 = keras.layers.Dense(hidden_1_dim, activation='relu')(inputs)\n",
    "    outputs = keras.layers.Dense(1,activation='tanh')(hidden_layer_1)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.900878800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def deepff(input_dim,hidden_1_dim = 64, hidden_2_dim = 32, hidden_3_dim = 32):\n",
    "    inputs = keras.layers.Input(shape=(input_dim))\n",
    "    hidden_layer_1 = keras.layers.Dense(hidden_1_dim, activation='relu')(inputs)\n",
    "    hidden_layer_2 = keras.layers.Dense(hidden_2_dim, activation='tanh')(hidden_layer_1)\n",
    "    hidden_layer_3 = keras.layers.Dense(hidden_3_dim, activation='relu')(hidden_layer_2)\n",
    "    outputs = keras.layers.Dense(1,activation='tanh')(hidden_layer_3)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.902883500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "model = slff_relu(input_dim)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.903387700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=200, batch_size=20, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.905524800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.906029200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot test data predictions\n",
    "def plot_pred(y_test,y_pred,period=500):\n",
    "    plt.figure()\n",
    "    plt.plot(y_test[-period:], \"b\", label=\"Actuals\")\n",
    "    plt.plot(y_pred[-period:], \"r\", label=\"Predictions\")\n",
    "    plt.title(\"Actuals vs Predictions\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_pred(y_test,y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.907034200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Task 6: Model Evaluation\n",
    "\n",
    "Evaluated model-based ARIMA and pure LSTM forecasters on test set\n",
    "\n",
    "Compared RMSE and MAPE error metrics\n",
    "\n",
    "ARIMA has lower error metrics compared to LSTM\n",
    "\n",
    "LSTM may improve with tuning hyperparameters, more data\n",
    "\n",
    "Ensembling models could combine strengths of each approach\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Compute and plot the test data errors\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m errors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqueeze(\u001B[43my_test\u001B[49m) \u001B[38;5;241m-\u001B[39m np\u001B[38;5;241m.\u001B[39msqueeze(y_pred)\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(errors)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute and plot the test data errors\n",
    "errors = np.squeeze(y_test) - np.squeeze(y_pred)\n",
    "plt.plot(errors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.971195400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def multistep_prediction(H, model, X_pred,residuals=[]):\n",
    "    y_pred_multi = []\n",
    "    X_pred_multi = []\n",
    "\n",
    "    for t in range(H):\n",
    "        X_pred = np.array(X_pred.reshape(1,len(X_pred)))\n",
    "        new_y= float(model.predict(X_pred))\n",
    "\n",
    "        y_pred_multi.append(float(new_y))\n",
    "        X_pred_multi.append(list(X_pred[0]))\n",
    "\n",
    "        X_pred = X_pred_multi[t][:-1]\n",
    "        if len(residuals) == 0:\n",
    "            X_pred.insert(0,new_y)\n",
    "        else:\n",
    "            X_pred.insert(0,(new_y+np.random.choice(residuals)))\n",
    "        X_pred = np.array(X_pred)\n",
    "\n",
    "    return y_pred_multi, X_pred_multi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.985017900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "H =5\n",
    "X_test_multi = X_test[-H:,:]\n",
    "y_test_multi = y_test[-H:]\n",
    "\n",
    "\n",
    "X_pred = X_test_multi[0,:]\n",
    "\n",
    "y_pred_multi, X_pred_multi = multistep_prediction(H,model,X_pred)\n",
    "plot_pred(y_test_multi, y_pred_multi)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.986020800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "residuals = np.squeeze(y_train) - np.squeeze(model.predict(X_train))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.988022800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bootstrap iterations\n",
    "K = 100\n",
    "\n",
    "# Prepare first input to multistep bootsrtap loop\n",
    "X_pred = X_test_multi[0,:]\n",
    "y_pred_bootstrap = []\n",
    "\n",
    "# Use multistep prediction to generate bootstrap data,\n",
    "# List of training residuals to sample from passed in as fourth argument\n",
    "\n",
    "for k in range(K):\n",
    "    y_pred_multi, X_pred_multi = multistep_prediction(H,model,X_pred,residuals)\n",
    "    y_pred_bootstrap.append(y_pred_multi)\n",
    "    # store y predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.990108900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Useful utility method for transposing lists of lists\n",
    "def transposed_2d_list(l):\n",
    "    return [[row[i] for row in l] for i in range(len(l[0]))]\n",
    "\n",
    "plt.plot(transposed_2d_list(y_pred_bootstrap[-5:]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.992114100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bootstrap_predictions = pd.DataFrame(index = df_cyclists.index.values[-H:])\n",
    "\n",
    "for pctl in range(0,101,10):\n",
    "    bootstrap_predictions[str(pctl)] = np.percentile(y_pred_bootstrap,pctl,axis=0)\n",
    "\n",
    "bootstrap_predictions.rename(columns={'50': \"median\"}, inplace=True)\n",
    "bootstrap_predictions['actuals'] = y_test[-H:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.993112300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot some deciles\n",
    "fig, ax_bootstrap_2 = plt.subplots()\n",
    "bootstrap_predictions['actuals'].plot(color = 'blue', label='Actuals', ax=ax_bootstrap_2)\n",
    "bootstrap_predictions['median'].plot(color = 'red',label = 'Median prediction', ax=ax_bootstrap_2 )\n",
    "bootstrap_predictions['10'].plot(color = 'green',label = '10th percentile', ax=ax_bootstrap_2 )\n",
    "bootstrap_predictions['20'].plot(color = 'orange',label = '20th percentile', ax=ax_bootstrap_2 )\n",
    "bootstrap_predictions['80'].plot(color = 'orange',label = '80th percentile', ax=ax_bootstrap_2 )\n",
    "bootstrap_predictions['90'].plot(color = 'grey',label = '90th percentile', ax=ax_bootstrap_2 )\n",
    "plt.legend(loc = 'lower left', fontsize = 12)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.995106100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot interval with fill\n",
    "fig, ax_bootstrap = plt.subplots()\n",
    "bootstrap_predictions['actuals'].plot(color='blue', label='Actuals', ax=ax_bootstrap)\n",
    "bootstrap_predictions['median'].plot(color = 'red',label = 'Median prediction', ax=ax_bootstrap )\n",
    "bootstrap_predictions['10'].plot(color = 'grey', label = '10th percentile', ax=ax_bootstrap )\n",
    "bootstrap_predictions['90'].plot(color = 'grey', label = '90th percentile', ax=ax_bootstrap )\n",
    "plt.legend(loc = 'lower left', fontsize = 12)\n",
    "\n",
    "x = df_cyclists.index.values[-H:]\n",
    "plt.fill_between(x, bootstrap_predictions['10'], bootstrap_predictions['90'], color='grey', alpha=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.996110300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def rmse(y_true,y_pred):\n",
    "    return mse(y_true,y_pred)**(0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.997111400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mae(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.998108900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rmse(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:18.999111500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mae(bootstrap_predictions['actuals'],bootstrap_predictions['median'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:19.000106700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_pinball_loss as mpl\n",
    "mpl(bootstrap_predictions['actuals'],bootstrap_predictions['median'], alpha=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-02T14:46:19.001110300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
